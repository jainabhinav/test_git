{"parameters":[{"name":"bid","type":"column","metadata":{"description":"","tags":[],"mappings":[]}}],"isCustomSchemaEnabled":false,"code":"var MIN_BID:   org.apache.spark.sql.Column = lit(0.01)\n  var MAX_BID:   org.apache.spark.sql.Column = lit(1000.0)\n  var BID_SCALE: org.apache.spark.sql.Column = lit(1000000.0)\n\n  var MIN_BUCKET: org.apache.spark.sql.Column =\n    (MIN_BID * BID_SCALE).cast(IntegerType)\n\n  var MAX_BUCKET: org.apache.spark.sql.Column =\n    (MAX_BID * BID_SCALE).cast(IntegerType)\n\n  var BUCKET_SIZE: org.apache.spark.sql.Column =\n    ((log10(MAX_BID) - log10(MIN_BID)) / lit(1500)).cast(DoubleType)\n\n  var l_bid:        org.apache.spark.sql.Column = lit(0)\n  var l_bid_bucket: org.apache.spark.sql.Column = lit(0)\n  l_bid = when(is_not_null(bid).cast(BooleanType), bid)\n    .otherwise(l_bid)\n    .cast(DoubleType)\n  l_bid_bucket = when(\n    l_bid > lit(0),\n    when(l_bid <= MIN_BID,    MIN_BUCKET)\n      .when(l_bid >= MAX_BID, MAX_BUCKET)\n      .otherwise(\n        floor(\n          pow(lit(10),\n              (decimal_round(log10(l_bid) / BUCKET_SIZE, 0) * BUCKET_SIZE)\n                .cast(DoubleType)\n          ) * BID_SCALE\n        )\n      )\n  ).otherwise(l_bid_bucket).cast(IntegerType)\n  l_bid_bucket","language":"scala","description":""}